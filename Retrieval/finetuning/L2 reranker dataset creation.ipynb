{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Passages</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777e7a14-fea3-4c37-a0e6-9ffb50024d5c</td>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>[{'DocumentID': 1, 'PassageID': '14.2.3.Guidan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0eb99ea8-3810-492c-9986-7739006b5708</td>\n",
       "      <td>Are there any exceptions or specific circumsta...</td>\n",
       "      <td>[{'DocumentID': 19, 'PassageID': '100)', 'Pass...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d34e3516-f053-4652-a0ac-ede703144b9a</td>\n",
       "      <td>What type of procedures must a Third Party Pro...</td>\n",
       "      <td>[{'DocumentID': 3, 'PassageID': '20.14.1.(2)',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6d876d32-7557-4149-875e-8c66f13f3485</td>\n",
       "      <td>Are there any exceptions or specific circumsta...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': '4.15.16', 'P...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2efd28f4-8677-4f05-82cd-d9989fb72409</td>\n",
       "      <td>What specific areas of inventory and delivery ...</td>\n",
       "      <td>[{'DocumentID': 34, 'PassageID': '35)', 'Passa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>b7f623dc-3b61-447f-b481-d47af4115d07</td>\n",
       "      <td>Your petroleum reporting entity is finalizing ...</td>\n",
       "      <td>[{'DocumentID': 31, 'PassageID': '10)', 'Passa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>cd8b132c-30b0-4322-bd65-e685a5237ad9</td>\n",
       "      <td>Can the regulatory authority provide guidance ...</td>\n",
       "      <td>[{'DocumentID': 33, 'PassageID': '113)', 'Pass...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>eb183134-d0be-4a3c-a935-7a39e9831fef</td>\n",
       "      <td>What should the detailed limit structure for a...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': 'APP4.A4.1.Gu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>c82f4441-bd41-4587-b59c-de77576370ad</td>\n",
       "      <td>In cases where an Authorised Person's internal...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': 'APP6.A6.9.2....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>235c1a96-e7b2-4812-bd48-4fcc4d4f4202</td>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>[{'DocumentID': 14, 'PassageID': 'Part 6.Chapt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                QuestionID  \\\n",
       "0     777e7a14-fea3-4c37-a0e6-9ffb50024d5c   \n",
       "1     0eb99ea8-3810-492c-9986-7739006b5708   \n",
       "2     d34e3516-f053-4652-a0ac-ede703144b9a   \n",
       "3     6d876d32-7557-4149-875e-8c66f13f3485   \n",
       "4     2efd28f4-8677-4f05-82cd-d9989fb72409   \n",
       "...                                    ...   \n",
       "2781  b7f623dc-3b61-447f-b481-d47af4115d07   \n",
       "2782  cd8b132c-30b0-4322-bd65-e685a5237ad9   \n",
       "2783  eb183134-d0be-4a3c-a935-7a39e9831fef   \n",
       "2784  c82f4441-bd41-4587-b59c-de77576370ad   \n",
       "2785  235c1a96-e7b2-4812-bd48-4fcc4d4f4202   \n",
       "\n",
       "                                               Question  \\\n",
       "0     Can the ADGM provide clarity on the level of d...   \n",
       "1     Are there any exceptions or specific circumsta...   \n",
       "2     What type of procedures must a Third Party Pro...   \n",
       "3     Are there any exceptions or specific circumsta...   \n",
       "4     What specific areas of inventory and delivery ...   \n",
       "...                                                 ...   \n",
       "2781  Your petroleum reporting entity is finalizing ...   \n",
       "2782  Can the regulatory authority provide guidance ...   \n",
       "2783  What should the detailed limit structure for a...   \n",
       "2784  In cases where an Authorised Person's internal...   \n",
       "2785  Can you elucidate the extent to which sharehol...   \n",
       "\n",
       "                                               Passages  Group  \n",
       "0     [{'DocumentID': 1, 'PassageID': '14.2.3.Guidan...      2  \n",
       "1     [{'DocumentID': 19, 'PassageID': '100)', 'Pass...      2  \n",
       "2     [{'DocumentID': 3, 'PassageID': '20.14.1.(2)',...      1  \n",
       "3     [{'DocumentID': 13, 'PassageID': '4.15.16', 'P...      3  \n",
       "4     [{'DocumentID': 34, 'PassageID': '35)', 'Passa...      3  \n",
       "...                                                 ...    ...  \n",
       "2781  [{'DocumentID': 31, 'PassageID': '10)', 'Passa...      1  \n",
       "2782  [{'DocumentID': 33, 'PassageID': '113)', 'Pass...      3  \n",
       "2783  [{'DocumentID': 13, 'PassageID': 'APP4.A4.1.Gu...      1  \n",
       "2784  [{'DocumentID': 13, 'PassageID': 'APP6.A6.9.2....     10  \n",
       "2785  [{'DocumentID': 14, 'PassageID': 'Part 6.Chapt...      2  \n",
       "\n",
       "[2786 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json(\"regnlp/ObliQADataset/ObliQA_test.json\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "def load_json_files_from_directory(directory_path):\n",
    "  \"\"\"Loads all JSON files from a given directory into a list of JSON objects.\"\"\"\n",
    "  json_files = glob.glob(directory_path + \"/*.json\")\n",
    "  json_data_list = []\n",
    "  for json_file in json_files:\n",
    "    with open(json_file, 'r') as f:\n",
    "      try:\n",
    "        json_data = json.load(f)\n",
    "        json_data_list.append((json_file, json_data))\n",
    "      except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {json_file}: {e}\")\n",
    "  return json_data_list\n",
    "\n",
    "\n",
    "directory_path = \"regnlp/ObliQADataset/StructuredRegulatoryDocuments\"\n",
    "json_data_list = load_json_files_from_directory(directory_path)\n",
    "len(json_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_json_data = [passage for json_file, json_data in json_data_list for passage in json_data]\n",
    "len(flattened_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_json_data_dict = {passage[\"ID\"]: passage for passage in flattened_json_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_json_data_dict_dp_id = {f'{passage[\"DocumentID\"]}:{passage[\"PassageID\"]}'.replace(' ', '_'): passage for passage in flattened_json_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://gist.githubusercontent.com/kwang2049/63ed76eb0f4d79ca81caecdb06897bfb/raw/1d86978275d666dff904fba65a34ce3e71b3cf1d/bm25.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup your paths appropriately\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-11.0.23.0.9-2.el7_9.x86_64/bin/java\"\n",
    "os.environ[\"JVM_PATH\"] = \"/usr/lib/jvm/java-11-openjdk-11.0.23.0.9-2.el7_9.x86_64/lib/server/libjvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Xmx5g\n",
      "Converting to pyserini format: 100%|███████████████████████████████████████████████████████████████████████████████████████| 13732/13732 [00:00<00:00, 109078.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2024-11-24 01:25:41,570 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2024-11-24 01:25:41,572 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2024-11-24 01:25:41,572 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2024-11-24 01:25:41,572 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: ./index/corpus\n",
      "2024-11-24 01:25:41,573 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2024-11-24 01:25:41,573 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2024-11-24 01:25:41,573 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 12\n",
      "2024-11-24 01:25:41,573 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2024-11-24 01:25:41,574 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2024-11-24 01:25:41,574 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2024-11-24 01:25:41,574 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2024-11-24 01:25:41,574 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? true\n",
      "2024-11-24 01:25:41,574 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? true\n",
      "2024-11-24 01:25:41,575 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? false\n",
      "2024-11-24 01:25:41,575 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? false\n",
      "2024-11-24 01:25:41,575 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: [title]\n",
      "2024-11-24 01:25:41,575 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2024-11-24 01:25:41,576 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2024-11-24 01:25:41,576 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2024-11-24 01:25:41,576 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: ./index\n",
      "2024-11-24 01:25:41,578 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2024-11-24 01:25:41,586 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2024-11-24 01:25:41,587 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2024-11-24 01:25:41,587 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2024-11-24 01:25:41,587 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2024-11-24 01:25:41,685 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 12 threads initialized.\n",
      "2024-11-24 01:25:41,685 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in ./index/corpus\n",
      "2024-11-24 01:25:41,686 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 1 file found\n",
      "2024-11-24 01:25:41,687 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2024-11-24 01:25:42,866 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - corpus/texts.jsonl: 13732 docs added.\n",
      "2024-11-24 01:25:43,553 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 13,732 documents indexed\n",
      "2024-11-24 01:25:43,553 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2024-11-24 01:25:43,553 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:           13,732\n",
      "2024-11-24 01:25:43,553 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2024-11-24 01:25:43,553 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2024-11-24 01:25:43,554 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2024-11-24 01:25:43,554 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "2024-11-24 01:25:43,558 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 13,732 documents indexed in 00:00:01\n"
     ]
    }
   ],
   "source": [
    "from bm25 import BM25, Document, Query\n",
    "\n",
    "bm25 = BM25()\n",
    "ndocs = 40\n",
    "collection = []\n",
    "for i in range(1, ndocs + 1):\n",
    "    with open(os.path.join(\"regnlp/ObliQADataset/StructuredRegulatoryDocuments\", f\"{i}.json\")) as f:\n",
    "        doc = json.load(f)\n",
    "        for psg in doc:\n",
    "          collection.append(Document(psg[\"ID\"], \"\", psg[\"PassageID\"] + \" \" + psg[\"Passage\"]))\n",
    "bm25.index(iter(collection), len(collection), \"./index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query batch: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2786/2786 [00:08<00:00, 340.09it/s]\n"
     ]
    }
   ],
   "source": [
    "retrieved = bm25.search(\n",
    "    queries=list(Query(*tup) for tup in zip(list(train_df[\"QuestionID\"]), list(train_df[\"Question\"]))),\n",
    "    index_path=\"./index\",\n",
    "    topk=50,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"RetrievedPassages\"] = train_df[\"QuestionID\"].apply(lambda x: [flattened_json_data_dict[doc.docid] for doc in retrieved[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2786/2786 [00:00<00:00, 7196.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "197459"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_data = []\n",
    "\n",
    "for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    question_id = row[\"QuestionID\"]\n",
    "    question = row[\"Question\"]\n",
    "    positive_passages = row[\"Passages\"]\n",
    "    positive_passages = [passage[\"Passage\"] for passage in positive_passages]\n",
    "    negative_passages = list(filter(lambda x: x[\"Passage\"] not in positive_passages, row[\"RetrievedPassages\"]))\n",
    "    negative_passages = [passage[\"Passage\"] for passage in negative_passages]\n",
    "    random_negative_passages = list(filter(lambda x: x[\"Passage\"] not in positive_passages, random.sample(flattened_json_data, 5)))\n",
    "    random_negative_passages = [passage[\"Passage\"] for passage in random_negative_passages]\n",
    "    for pos_psg in positive_passages:\n",
    "        for neg_psg in negative_passages:\n",
    "            triplet_data.append({\n",
    "                \"question\": question,\n",
    "                \"positive_passage\": pos_psg,\n",
    "                \"negative_passage\": neg_psg,\n",
    "                \"type\": \"hard\"\n",
    "            })\n",
    "        for neg_psg in random_negative_passages:\n",
    "            triplet_data.append({\n",
    "                \"question\": question,\n",
    "                \"positive_passage\": pos_psg,\n",
    "                \"negative_passage\": neg_psg,\n",
    "                \"type\": \"easy\"\n",
    "            })\n",
    "\n",
    "len(triplet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>positive_passage</th>\n",
       "      <th>negative_passage</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Relevant Persons should comply with guidance i...</td>\n",
       "      <td>The records maintained by a Relevant Person mu...</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Relevant Persons should comply with guidance i...</td>\n",
       "      <td>REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Relevant Persons should comply with guidance i...</td>\n",
       "      <td>API REQUIREMENTS\\nData\\nTo enable the interope...</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Relevant Persons should comply with guidance i...</td>\n",
       "      <td>API REQUIREMENTS\\nData\\nTo enable the interope...</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Relevant Persons should comply with guidance i...</td>\n",
       "      <td>REGULATORY REQUIREMENTS - SPOT COMMODITY ACTIV...</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197454</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>Requirements for all disclosures. A disclosure...</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197455</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>The GEN rules set out the Regulator requiremen...</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197456</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>The activities. Operating a Multilateral Tradi...</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197457</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>A dilution levy or adjustment means a charge o...</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197458</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>A person may not be required by or under these...</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197459 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       Can the ADGM provide clarity on the level of d...   \n",
       "1       Can the ADGM provide clarity on the level of d...   \n",
       "2       Can the ADGM provide clarity on the level of d...   \n",
       "3       Can the ADGM provide clarity on the level of d...   \n",
       "4       Can the ADGM provide clarity on the level of d...   \n",
       "...                                                   ...   \n",
       "197454  Can you elucidate the extent to which sharehol...   \n",
       "197455  Can you elucidate the extent to which sharehol...   \n",
       "197456  Can you elucidate the extent to which sharehol...   \n",
       "197457  Can you elucidate the extent to which sharehol...   \n",
       "197458  Can you elucidate the extent to which sharehol...   \n",
       "\n",
       "                                         positive_passage  \\\n",
       "0       Relevant Persons should comply with guidance i...   \n",
       "1       Relevant Persons should comply with guidance i...   \n",
       "2       Relevant Persons should comply with guidance i...   \n",
       "3       Relevant Persons should comply with guidance i...   \n",
       "4       Relevant Persons should comply with guidance i...   \n",
       "...                                                   ...   \n",
       "197454  Without prejudice to the Resolution Safeguards...   \n",
       "197455  Without prejudice to the Resolution Safeguards...   \n",
       "197456  Without prejudice to the Resolution Safeguards...   \n",
       "197457  Without prejudice to the Resolution Safeguards...   \n",
       "197458  Without prejudice to the Resolution Safeguards...   \n",
       "\n",
       "                                         negative_passage  type  \n",
       "0       The records maintained by a Relevant Person mu...  hard  \n",
       "1       REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...  hard  \n",
       "2       API REQUIREMENTS\\nData\\nTo enable the interope...  hard  \n",
       "3       API REQUIREMENTS\\nData\\nTo enable the interope...  hard  \n",
       "4       REGULATORY REQUIREMENTS - SPOT COMMODITY ACTIV...  hard  \n",
       "...                                                   ...   ...  \n",
       "197454  Requirements for all disclosures. A disclosure...  easy  \n",
       "197455  The GEN rules set out the Regulator requiremen...  easy  \n",
       "197456  The activities. Operating a Multilateral Tradi...  easy  \n",
       "197457  A dilution levy or adjustment means a charge o...  easy  \n",
       "197458  A person may not be required by or under these...  easy  \n",
       "\n",
       "[197459 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_df = pd.DataFrame(triplet_data)\n",
    "triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "easy     18327\n",
       "hard    179132\n",
       "Name: question, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_df.groupby(\"type\")[\"question\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_df.to_parquet(\"regnlp/ObliQADataset/triplet_data_bm25_50_random_5_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='sentence-transformers/all-mpnet-base-v2'\n",
    "model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(e, task=None):\n",
    "    if len(e) > 0:\n",
    "        if task is not None:\n",
    "            embeddings = torch.Tensor(model.encode([k.lower().split(\" \") for k in e], task=task, prompt_name=task, show_progress_bar = False))\n",
    "        else:\n",
    "            embeddings = torch.Tensor(model.encode([k.lower() for k in e], batch_size=32, show_progress_bar = False))\n",
    "        return np.array(F.normalize(embeddings, p=2, dim=1))\n",
    "    else:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "all_sentences = {}\n",
    "\n",
    "for file, data in tqdm(json_data_list[0:]):\n",
    "\n",
    "    from blingfire import text_to_sentences\n",
    "    sentences = {file.split(\"/\")[-1].split(\".json\")[0]+\":\"+e['PassageID']: text_to_sentences(e['Passage'].replace(\"\\u200e\", \"\").replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \"\\t\")).split(\"\\n\") for e in data}\n",
    "    sentences = {file.split(\"/\")[-1].split(\".json\")[0]+\":\"+e['PassageID']: e['Passage'].replace(\"\\u200e\", \"\").replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \"\\t\") for e in data}\n",
    "    all_sentences |= sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.max_seq_length > 1024:\n",
    "    model.max_seq_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def compute_batch_embeddings(sentences, batch_size=32):\n",
    "    output_embedding = []\n",
    "    for e in tqdm(range(0, len(sentences), batch_size)):\n",
    "        try:\n",
    "            output_embedding.append([e for e in get_embedding(sentences[e:e+batch_size])])\n",
    "        except:\n",
    "            print(sentences[e:e+batch_size])\n",
    "            raise Exception\n",
    "\n",
    "    return list(chain(*output_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "for each_sentence, embedding in zip(all_sentences.keys(), compute_batch_embeddings(list(all_sentences.values()))):\n",
    "    embeddings[each_sentence] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22295/22295 [00:00<00:00, 424506.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 697/697 [01:02<00:00, 11.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_dataset_map = {}\n",
    "train_dataset_ind = []\n",
    "with open(f'regnlp/ObliQADataset/ObliQA_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    questions = []\n",
    "    for each_question in tqdm(data[:]):\n",
    "        questions.append(each_question['Question'])\n",
    "        train_dataset_map[each_question['QuestionID']] = [f\"{e['DocumentID']}:{e['PassageID'].replace(' ', '_')}\"for e in each_question['Passages']]\n",
    "        train_dataset_ind.append(each_question['QuestionID'])\n",
    "\n",
    "train_embeddings = np.array(compute_batch_embeddings(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'regnlp/ObliQADataset/ObliQA_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2786/2786 [00:00<00:00, 1640046.45it/s]\n",
      "  0%|                                                                                                                                         | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:07<00:00, 11.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2786/2786 [00:07<00:00, 355.98it/s]\n"
     ]
    }
   ],
   "source": [
    "hack_data = []\n",
    "\n",
    "with open(f'regnlp/ObliQADataset/ObliQA_test.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    questions = []\n",
    "    for each_question in tqdm(data[:]):\n",
    "        questions.append(each_question['Question'])\n",
    "\n",
    "    question_embeddings = compute_batch_embeddings(questions)\n",
    "\n",
    "    hack_scores = {}\n",
    "    for each_embedding, each_question in tqdm(zip(question_embeddings, data), total=len(data)):\n",
    "        relevant_passages = each_embedding.dot(train_embeddings.T)\n",
    "        indices = np.argsort(relevant_passages)\n",
    "\n",
    "        top_10_passages = indices[-50:]\n",
    "        hack_scores[each_question['QuestionID']] = relevant_passages[top_10_passages[-1]]\n",
    "        i = 0\n",
    "        cache_passages = set()\n",
    "        for e in top_10_passages:\n",
    "            for each_passage_id in train_dataset_map[train_dataset_ind[e]]:\n",
    "                if each_passage_id in cache_passages:\n",
    "                    continue\n",
    "                cache_passages.add(each_passage_id)\n",
    "                relevant_passage_dp_id_set = set([f\"{e['DocumentID']}:{e['PassageID'].replace(' ', '_')}\" for e in each_question['Passages']])\n",
    "                hack_data.append({\"question\": each_question['Question'], \"passage\": flattened_json_data_dict_dp_id[each_passage_id][\"Passage\"], \"similar\": each_passage_id in relevant_passage_dp_id_set, \"type\": \"hard\"})\n",
    "                # line = f\"{each_question['QuestionID']} 0 {each_passage_id} {i+1} {relevant_passages[e]} alg\"\n",
    "                # pred_rels.write(line + \"\\n\")\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>similar</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>An Authorised Person must implement and mainta...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>The Regulator may make Rules prescribing circu...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>Compliance: An Authorised Person must document...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120245</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Without prejudice to the Resolution Safeguards...</td>\n",
       "      <td>True</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120246</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>The Regulator may apply the Bail-in Tool only ...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120247</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>Subject to the section ‎31, the net proceeds o...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120248</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>A special manager shall have all the powers of...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120249</th>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>A transfer made under the Sale of Business Too...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       Can the ADGM provide clarity on the level of d...   \n",
       "1       Can the ADGM provide clarity on the level of d...   \n",
       "2       Can the ADGM provide clarity on the level of d...   \n",
       "3       Can the ADGM provide clarity on the level of d...   \n",
       "4       Can the ADGM provide clarity on the level of d...   \n",
       "...                                                   ...   \n",
       "120245  Can you elucidate the extent to which sharehol...   \n",
       "120246  Can you elucidate the extent to which sharehol...   \n",
       "120247  Can you elucidate the extent to which sharehol...   \n",
       "120248  Can you elucidate the extent to which sharehol...   \n",
       "120249  Can you elucidate the extent to which sharehol...   \n",
       "\n",
       "                                                  passage  similar  type  \n",
       "0       An Authorised Person must implement and mainta...    False  hard  \n",
       "1       REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...    False  hard  \n",
       "2       REGULATORY REQUIREMENTS FOR AUTHORISED PERSONS...    False  hard  \n",
       "3       The Regulator may make Rules prescribing circu...    False  hard  \n",
       "4       Compliance: An Authorised Person must document...    False  hard  \n",
       "...                                                   ...      ...   ...  \n",
       "120245  Without prejudice to the Resolution Safeguards...     True  hard  \n",
       "120246  The Regulator may apply the Bail-in Tool only ...    False  hard  \n",
       "120247  Subject to the section ‎31, the net proceeds o...    False  hard  \n",
       "120248  A special manager shall have all the powers of...    False  hard  \n",
       "120249  A transfer made under the Sale of Business Too...    False  hard  \n",
       "\n",
       "[120250 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df = pd.DataFrame(hack_data)\n",
    "labelled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df.to_parquet(\"regnlp/ObliQADataset/labelled_data_hack_50_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = \"ObliQA\"\n",
    "model_type = \"e5-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from qdrant_client.http import models\n",
    "\n",
    "\n",
    "if not client.collection_exists(collection_name=col_name):\n",
    "        client.create_collection(\n",
    "            collection_name=col_name,\n",
    "            vectors_config=VectorParams(\n",
    "                size=768,\n",
    "                distance=Distance.DOT\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(\n",
    "                ef_construct=250,\n",
    "                m=32\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60f3d71d-a67e-48ae-b737-154ebcc69c97</td>\n",
       "      <td>[-0.22949139773845673, -0.8091111183166504, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0487a271-74a6-46d7-807c-3eab39adc217</td>\n",
       "      <td>[-0.11922454833984375, -0.7714837789535522, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29e455a6-4550-4a6e-a2d7-94ada2de47ac</td>\n",
       "      <td>[-0.18683482706546783, -0.7842036485671997, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b126980-12f0-4e22-a36a-bfcfe99855f3</td>\n",
       "      <td>[-0.12334126979112625, -0.8295338153839111, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6963b293-a008-46b6-b229-09eff7283ebe</td>\n",
       "      <td>[-0.22615359723567963, -0.9278210401535034, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>6b4ad3d0-9455-4687-ae49-65d61e2bb31e</td>\n",
       "      <td>[-0.1727040708065033, -0.688385009765625, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>2c33381e-7252-4748-9276-3b488e2ebebf</td>\n",
       "      <td>[-0.21498960256576538, -0.7898073792457581, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>df9986be-f35e-4cae-a6c5-f9c1cf9304a7</td>\n",
       "      <td>[-0.20870253443717957, -0.8095766305923462, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>985c30a3-7635-452e-ad3f-2c8c77694018</td>\n",
       "      <td>[-0.37213513255119324, -0.7387443780899048, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13731</th>\n",
       "      <td>20fb6d34-d5a9-4518-a07a-8b2b46202fa8</td>\n",
       "      <td>[-0.30817389488220215, -0.805921196937561, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13732 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      60f3d71d-a67e-48ae-b737-154ebcc69c97   \n",
       "1      0487a271-74a6-46d7-807c-3eab39adc217   \n",
       "2      29e455a6-4550-4a6e-a2d7-94ada2de47ac   \n",
       "3      4b126980-12f0-4e22-a36a-bfcfe99855f3   \n",
       "4      6963b293-a008-46b6-b229-09eff7283ebe   \n",
       "...                                     ...   \n",
       "13727  6b4ad3d0-9455-4687-ae49-65d61e2bb31e   \n",
       "13728  2c33381e-7252-4748-9276-3b488e2ebebf   \n",
       "13729  df9986be-f35e-4cae-a6c5-f9c1cf9304a7   \n",
       "13730  985c30a3-7635-452e-ad3f-2c8c77694018   \n",
       "13731  20fb6d34-d5a9-4518-a07a-8b2b46202fa8   \n",
       "\n",
       "                                                    embd  \n",
       "0      [-0.22949139773845673, -0.8091111183166504, -0...  \n",
       "1      [-0.11922454833984375, -0.7714837789535522, -0...  \n",
       "2      [-0.18683482706546783, -0.7842036485671997, -0...  \n",
       "3      [-0.12334126979112625, -0.8295338153839111, -0...  \n",
       "4      [-0.22615359723567963, -0.9278210401535034, -0...  \n",
       "...                                                  ...  \n",
       "13727  [-0.1727040708065033, -0.688385009765625, -0.8...  \n",
       "13728  [-0.21498960256576538, -0.7898073792457581, -0...  \n",
       "13729  [-0.20870253443717957, -0.8095766305923462, -0...  \n",
       "13730  [-0.37213513255119324, -0.7387443780899048, -0...  \n",
       "13731  [-0.30817389488220215, -0.805921196937561, -0....  \n",
       "\n",
       "[13732 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = pd.read_parquet(\"regnlp/ObliQADataset/ObliQA_e5_base_v2_finetuned_embd.parquet\")\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                      | 0/13732 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13732/13732 [00:03<00:00, 4499.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "import tqdm \n",
    "tqdm.tqdm.pandas()\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "LOAD_PRECOMPUTED = True\n",
    "\n",
    "if LOAD_PRECOMPUTED:\n",
    "    batch_list = []\n",
    "    for index, row in tqdm.tqdm(embeddings_df.iterrows(), total=len(embeddings_df)):\n",
    "        joined_data = flattened_json_data_dict[row[\"id\"]]\n",
    "        element_data = {\n",
    "            \"ID\": row[\"id\"],\n",
    "            \"embd\": row[\"embd\"].tolist(),\n",
    "        }\n",
    "        element_data[\"metadata\"] = dict(joined_data)\n",
    "        element_data[\"metadata\"][\"DocumentID\"] = int(element_data[\"metadata\"][\"DocumentID\"])\n",
    "        element_data[\"metadata\"][\"ID\"] = row[\"id\"]\n",
    "        batch_list.append(element_data)\n",
    "        if index % BATCH_SIZE == 0:\n",
    "            client.upsert(\n",
    "                collection_name=col_name,\n",
    "                wait=True,\n",
    "                points=[\n",
    "                    PointStruct(id=element[\"ID\"], vector=element[\"embd\"], payload=element[\"metadata\"])\n",
    "                    for element in batch_list\n",
    "                ],\n",
    "            )\n",
    "            batch_list = []\n",
    "    if len(batch_list) > 0:\n",
    "        client.upsert(\n",
    "                collection_name=col_name,\n",
    "                wait=True,\n",
    "                points=[\n",
    "                    PointStruct(id=element[\"ID\"], vector=element[\"embd\"], payload=element[\"metadata\"])\n",
    "                    for element in batch_list\n",
    "                ],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Passages</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777e7a14-fea3-4c37-a0e6-9ffb50024d5c</td>\n",
       "      <td>Can the ADGM provide clarity on the level of d...</td>\n",
       "      <td>[{'DocumentID': 1, 'PassageID': '14.2.3.Guidan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0eb99ea8-3810-492c-9986-7739006b5708</td>\n",
       "      <td>Are there any exceptions or specific circumsta...</td>\n",
       "      <td>[{'DocumentID': 19, 'PassageID': '100)', 'Pass...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d34e3516-f053-4652-a0ac-ede703144b9a</td>\n",
       "      <td>What type of procedures must a Third Party Pro...</td>\n",
       "      <td>[{'DocumentID': 3, 'PassageID': '20.14.1.(2)',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6d876d32-7557-4149-875e-8c66f13f3485</td>\n",
       "      <td>Are there any exceptions or specific circumsta...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': '4.15.16', 'P...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2efd28f4-8677-4f05-82cd-d9989fb72409</td>\n",
       "      <td>What specific areas of inventory and delivery ...</td>\n",
       "      <td>[{'DocumentID': 34, 'PassageID': '35)', 'Passa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>b7f623dc-3b61-447f-b481-d47af4115d07</td>\n",
       "      <td>Your petroleum reporting entity is finalizing ...</td>\n",
       "      <td>[{'DocumentID': 31, 'PassageID': '10)', 'Passa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>cd8b132c-30b0-4322-bd65-e685a5237ad9</td>\n",
       "      <td>Can the regulatory authority provide guidance ...</td>\n",
       "      <td>[{'DocumentID': 33, 'PassageID': '113)', 'Pass...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>eb183134-d0be-4a3c-a935-7a39e9831fef</td>\n",
       "      <td>What should the detailed limit structure for a...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': 'APP4.A4.1.Gu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>c82f4441-bd41-4587-b59c-de77576370ad</td>\n",
       "      <td>In cases where an Authorised Person's internal...</td>\n",
       "      <td>[{'DocumentID': 13, 'PassageID': 'APP6.A6.9.2....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>235c1a96-e7b2-4812-bd48-4fcc4d4f4202</td>\n",
       "      <td>Can you elucidate the extent to which sharehol...</td>\n",
       "      <td>[{'DocumentID': 14, 'PassageID': 'Part 6.Chapt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                QuestionID  \\\n",
       "0     777e7a14-fea3-4c37-a0e6-9ffb50024d5c   \n",
       "1     0eb99ea8-3810-492c-9986-7739006b5708   \n",
       "2     d34e3516-f053-4652-a0ac-ede703144b9a   \n",
       "3     6d876d32-7557-4149-875e-8c66f13f3485   \n",
       "4     2efd28f4-8677-4f05-82cd-d9989fb72409   \n",
       "...                                    ...   \n",
       "2781  b7f623dc-3b61-447f-b481-d47af4115d07   \n",
       "2782  cd8b132c-30b0-4322-bd65-e685a5237ad9   \n",
       "2783  eb183134-d0be-4a3c-a935-7a39e9831fef   \n",
       "2784  c82f4441-bd41-4587-b59c-de77576370ad   \n",
       "2785  235c1a96-e7b2-4812-bd48-4fcc4d4f4202   \n",
       "\n",
       "                                               Question  \\\n",
       "0     Can the ADGM provide clarity on the level of d...   \n",
       "1     Are there any exceptions or specific circumsta...   \n",
       "2     What type of procedures must a Third Party Pro...   \n",
       "3     Are there any exceptions or specific circumsta...   \n",
       "4     What specific areas of inventory and delivery ...   \n",
       "...                                                 ...   \n",
       "2781  Your petroleum reporting entity is finalizing ...   \n",
       "2782  Can the regulatory authority provide guidance ...   \n",
       "2783  What should the detailed limit structure for a...   \n",
       "2784  In cases where an Authorised Person's internal...   \n",
       "2785  Can you elucidate the extent to which sharehol...   \n",
       "\n",
       "                                               Passages  Group  \n",
       "0     [{'DocumentID': 1, 'PassageID': '14.2.3.Guidan...      2  \n",
       "1     [{'DocumentID': 19, 'PassageID': '100)', 'Pass...      2  \n",
       "2     [{'DocumentID': 3, 'PassageID': '20.14.1.(2)',...      1  \n",
       "3     [{'DocumentID': 13, 'PassageID': '4.15.16', 'P...      3  \n",
       "4     [{'DocumentID': 34, 'PassageID': '35)', 'Passa...      3  \n",
       "...                                                 ...    ...  \n",
       "2781  [{'DocumentID': 31, 'PassageID': '10)', 'Passa...      1  \n",
       "2782  [{'DocumentID': 33, 'PassageID': '113)', 'Pass...      3  \n",
       "2783  [{'DocumentID': 13, 'PassageID': 'APP4.A4.1.Gu...      1  \n",
       "2784  [{'DocumentID': 13, 'PassageID': 'APP6.A6.9.2....     10  \n",
       "2785  [{'DocumentID': 14, 'PassageID': 'Part 6.Chapt...      2  \n",
       "\n",
       "[2786 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(\"regnlp/ObliQADataset/ObliQA_test.json\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "MODEL_NAME = \"regnlp/e5-base-v2-finetuned/checkpoint-24800\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 348/348 [01:11<00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "vec_data = []\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TOP_K = 50\n",
    "\n",
    "pred_rels = open(\"test.pred_rels\", \"w\")\n",
    "\n",
    "batched_data = np.array_split(np.asarray(list(test_df.iterrows()), dtype=\"object\"), len(test_df) // BATCH_SIZE)\n",
    "for batched_row in tqdm.tqdm(batched_data, total=len(batched_data)):\n",
    "    doc_batch_dict = tokenizer([element[1]['Question'] for element in batched_row], padding=True, truncation=True, return_tensors='pt')\n",
    "    for key in doc_batch_dict:\n",
    "        doc_batch_dict[key] = doc_batch_dict[key].to(device)\n",
    "    query_embeddings_list = None\n",
    "    with torch.no_grad():\n",
    "        doc_outputs = model(**doc_batch_dict)\n",
    "        # doc_embeddings = last_token_pool(doc_outputs.last_hidden_state, doc_batch_dict['attention_mask'])\n",
    "        query_embeddings_list = average_pool(doc_outputs.last_hidden_state, doc_batch_dict['attention_mask'])\n",
    "        for key in doc_batch_dict:\n",
    "            doc_batch_dict[key] = doc_batch_dict[key].detach().cpu()\n",
    "    for i in range(len(query_embeddings_list)):\n",
    "        search_result = client.query_points(\n",
    "            collection_name=col_name,\n",
    "            query=query_embeddings_list[i].tolist(),\n",
    "            with_payload=True,\n",
    "            limit=TOP_K,\n",
    "            # search_params=models.SearchParams(hnsw_ef=128, exact=False),\n",
    "            search_params=models.SearchParams(exact=True),\n",
    "        ).points\n",
    "        relevant_passage_dp_id_set = set([f\"{e['DocumentID']}:{e['PassageID'].replace(' ', '_')}\" for e in batched_row[i][1][\"Passages\"]])\n",
    "        for j, hit in enumerate(sorted(search_result, key=lambda hit:hit.score, reverse=True)):\n",
    "            vec_data.append({\"question\": batched_row[i][1][\"Question\"], \"passage\": hit.payload[\"Passage\"], \n",
    "            \"similar\": f\"{hit.payload['DocumentID']}:{hit.payload['PassageID'].replace(' ', '_')}\" in relevant_passage_dp_id_set, \n",
    "            \"type\": \"hard\"})\n",
    "            pred_rels.write(f\"{batched_row[i][1]['QuestionID']} 0 {hit.id} {j+1} 10 alg\\n\")\n",
    "\n",
    "pred_rels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!regnlp/trec_eval/trec_eval -m recall.10 -m map_cut.10 regnlp/test_gt.trec regnlp/test.pred_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>similar</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If a PFP Client intends to use the exit facili...</td>\n",
       "      <td>DIGITAL SECURITIES – INTERMEDIARIES\\nThis sect...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If a PFP Client intends to use the exit facili...</td>\n",
       "      <td>MARKETS RULES – OFFERS OF SECURITIES TO THE PU...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If a PFP Client intends to use the exit facili...</td>\n",
       "      <td>Review Procedures for Identifying Entity Accou...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If a PFP Client intends to use the exit facili...</td>\n",
       "      <td>All Regulatory Returns prepared by the Authori...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If a PFP Client intends to use the exit facili...</td>\n",
       "      <td>DUE DILIGENCE FOR PRE-EXISTING INDIVIDUAL ACCO...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139395</th>\n",
       "      <td>Can a Recognised Body rely solely on its inter...</td>\n",
       "      <td>REGULATORY REQUIREMENTS\\nData Protection\\nFor ...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139396</th>\n",
       "      <td>Can a Recognised Body rely solely on its inter...</td>\n",
       "      <td>CRCOM. An Authorised Person must calculate its...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139397</th>\n",
       "      <td>Can a Recognised Body rely solely on its inter...</td>\n",
       "      <td>Subject to paragraphs C through E, each Report...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139398</th>\n",
       "      <td>Can a Recognised Body rely solely on its inter...</td>\n",
       "      <td>A Relevant Person must ensure that it does not...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139399</th>\n",
       "      <td>Can a Recognised Body rely solely on its inter...</td>\n",
       "      <td>Each Reporting Financial Institution shall est...</td>\n",
       "      <td>False</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       If a PFP Client intends to use the exit facili...   \n",
       "1       If a PFP Client intends to use the exit facili...   \n",
       "2       If a PFP Client intends to use the exit facili...   \n",
       "3       If a PFP Client intends to use the exit facili...   \n",
       "4       If a PFP Client intends to use the exit facili...   \n",
       "...                                                   ...   \n",
       "139395  Can a Recognised Body rely solely on its inter...   \n",
       "139396  Can a Recognised Body rely solely on its inter...   \n",
       "139397  Can a Recognised Body rely solely on its inter...   \n",
       "139398  Can a Recognised Body rely solely on its inter...   \n",
       "139399  Can a Recognised Body rely solely on its inter...   \n",
       "\n",
       "                                                  passage  similar  type  \n",
       "0       DIGITAL SECURITIES – INTERMEDIARIES\\nThis sect...    False  hard  \n",
       "1       MARKETS RULES – OFFERS OF SECURITIES TO THE PU...    False  hard  \n",
       "2       Review Procedures for Identifying Entity Accou...    False  hard  \n",
       "3       All Regulatory Returns prepared by the Authori...    False  hard  \n",
       "4       DUE DILIGENCE FOR PRE-EXISTING INDIVIDUAL ACCO...    False  hard  \n",
       "...                                                   ...      ...   ...  \n",
       "139395  REGULATORY REQUIREMENTS\\nData Protection\\nFor ...    False  hard  \n",
       "139396  CRCOM. An Authorised Person must calculate its...    False  hard  \n",
       "139397  Subject to paragraphs C through E, each Report...    False  hard  \n",
       "139398  A Relevant Person must ensure that it does not...    False  hard  \n",
       "139399  Each Reporting Financial Institution shall est...    False  hard  \n",
       "\n",
       "[139400 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df = pd.DataFrame(vec_data)\n",
    "labelled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df.to_parquet(\"regnlp/ObliQADataset/labelled_data_e5_finetuned_50_dev.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All sources\n",
    "\n",
    "After generating data for all sources and all splits (train, test, dev) of the ObliQADataset. We can combine all the sources and splits into a single files for splits\n",
    "\n",
    "We skipped BGE due to less compute constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "labelled_data_bm25_100_random_5.parquet\n",
    "labelled_data_bm25_100_random_5_dev.parquet\n",
    "labelled_data_bm25_100_random_5_test.parquet\n",
    "labelled_data_e5_finetuned_50.parquet\n",
    "labelled_data_e5_finetuned_50_dev.parquet\n",
    "labelled_data_e5_finetuned_50_test.parquet\n",
    "labelled_data_hack_50.parquet\n",
    "labelled_data_hack_50_dev.parquet\n",
    "labelled_data_hack_50_test.parquet\n",
    "\"\"\"\n",
    "\n",
    "# combine dev, test and other parquet files as 3 different dataframes\n",
    "labelled_data_dev = pd.concat([\n",
    "    pd.read_parquet(\"regnlp/ObliQADataset/labelled_data_bm25_100_random_5_dev.parquet\"),\n",
    "    pd.read_parquet(\"regnlp/ObliQADataset/labelled_data_e5_finetuned_50_dev.parquet\"),\n",
    "    pd.read_parquet(\"regnlp/ObliQADataset/labelled_data_hack_50_dev.parquet\")\n",
    "    ])\n",
    "labelled_data_test = pd.concat([\n",
    "    pd.read_parquet(\"regnlp/ObliQADataset/labelled_data_bm25_100_random_5_test.parquet\"),\n",
    "\tpd.read_parquet(\"regnlp/ObliQADataset/labelled_data_e5_finetuned_50_test.parquet\"),\n",
    "\tpd.read_parquet(\"regnlp/ObliQADataset/labelled_data_hack_50_test.parquet\")\n",
    "\t])\n",
    "labelled_data_other = pd.concat([\n",
    "    pd.read_parquet(\"regnlp/ObliQADataset/labelled_data_bm25_100_random_5.parquet\"),\n",
    "\tpd.read_parquet(\"regnlp/ObliQADataset/labelled_data_e5_finetuned_50.parquet\"),\n",
    "\tpd.read_parquet(\"regnlp/ObliQADataset/labelled_data_hack_50.parquet\")\n",
    "\t])\n",
    "\n",
    "# pretty print lengths of each data frames\n",
    "print(\"dev: \", len(labelled_data_dev))\n",
    "print(\"test: \", len(labelled_data_test))\n",
    "print(\"other: \", len(labelled_data_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates if types are different\n",
    "labelled_data_dev = labelled_data_dev.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "labelled_data_test = labelled_data_test.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "labelled_data_other = labelled_data_other.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "\n",
    "# pretty print lengths of each data frames\n",
    "print(\"dev: \", len(labelled_data_dev))\n",
    "print(\"test: \", len(labelled_data_test))\n",
    "print(\"other: \", len(labelled_data_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_dev = labelled_data_dev.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "labelled_data_test = labelled_data_test.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "labelled_data_other = labelled_data_other.drop_duplicates(subset=[\"question\", \"passage\", \"similar\"])\n",
    "\n",
    "print(\"dev: \", len(labelled_data_dev))\n",
    "print(\"test: \", len(labelled_data_test))\n",
    "print(\"other: \", len(labelled_data_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_dev = labelled_data_dev.drop_duplicates(subset=[\"question\", \"passage\"])\n",
    "labelled_data_test = labelled_data_test.drop_duplicates(subset=[\"question\", \"passage\"])\n",
    "labelled_data_other = labelled_data_other.drop_duplicates(subset=[\"question\", \"passage\"])\n",
    "\n",
    "print(\"dev: \", len(labelled_data_dev))\n",
    "print(\"test: \", len(labelled_data_test))\n",
    "print(\"other: \", len(labelled_data_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to parquet\n",
    "labelled_data_dev.to_parquet(\"regnlp/ObliQADataset/reg_nlp_labelled_data_dev.parquet\")\n",
    "labelled_data_test.to_parquet(\"regnlp/ObliQADataset/reg_nlp_labelled_data_test.parquet\")\n",
    "labelled_data_other.to_parquet(\"regnlp/ObliQADataset/reg_nlp_labelled_data_train.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
