{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 ReRanker Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T13:58:37.875835Z",
     "iopub.status.busy": "2025-01-19T13:58:37.875512Z",
     "iopub.status.idle": "2025-01-19T13:58:37.882356Z",
     "shell.execute_reply": "2025-01-19T13:58:37.881350Z",
     "shell.execute_reply.started": "2025-01-19T13:58:37.875809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade tqdm==4.66.5 blingfire einops accelerate>=0.26.0 datasets transformers[torch] sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:37.214573Z",
     "iopub.status.busy": "2025-01-19T14:05:37.214283Z",
     "iopub.status.idle": "2025-01-19T14:05:42.958961Z",
     "shell.execute_reply": "2025-01-19T14:05:42.958133Z",
     "shell.execute_reply.started": "2025-01-19T14:05:37.214544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:42.961631Z",
     "iopub.status.busy": "2025-01-19T14:05:42.961154Z",
     "iopub.status.idle": "2025-01-19T14:05:42.967133Z",
     "shell.execute_reply": "2025-01-19T14:05:42.966010Z",
     "shell.execute_reply.started": "2025-01-19T14:05:42.961600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Json Encoder with numpy support\n",
    "import numpy as np\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:42.968676Z",
     "iopub.status.busy": "2025-01-19T14:05:42.968397Z",
     "iopub.status.idle": "2025-01-19T14:05:53.548157Z",
     "shell.execute_reply": "2025-01-19T14:05:53.546639Z",
     "shell.execute_reply.started": "2025-01-19T14:05:42.968649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/RegNLP/ObliQADataset.git\n",
    "!git clone https://github.com/usnistgov/trec_eval.git\n",
    "!cd trec_eval && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:53.550365Z",
     "iopub.status.busy": "2025-01-19T14:05:53.549998Z",
     "iopub.status.idle": "2025-01-19T14:05:53.621757Z",
     "shell.execute_reply": "2025-01-19T14:05:53.620905Z",
     "shell.execute_reply.started": "2025-01-19T14:05:53.550333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_json_files_from_directory(directory_path):\n",
    "    \"\"\"Loads all JSON files from a given directory into a list of JSON objects.\"\"\"\n",
    "\n",
    "    json_files = glob.glob(directory_path + \"/*.json\")\n",
    "    json_data_list = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            try:\n",
    "                json_data = json.load(f)\n",
    "                json_data_list.append((json_file, json_data))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {json_file}: {e}\")\n",
    "    return json_data_list\n",
    "\n",
    "directory_path = \"ObliQADataset/StructuredRegulatoryDocuments\"\n",
    "json_data_list = load_json_files_from_directory(directory_path)\n",
    "flattened_json_data_list = [element for json_file, json_data in json_data_list for element in json_data]\n",
    "\n",
    "dp_id_to_id = {f'{element[\"DocumentID\"]}:{element[\"PassageID\"]}'.replace(' ', '_'):element[\"ID\"] for element in flattened_json_data_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:53.623501Z",
     "iopub.status.busy": "2025-01-19T14:05:53.623066Z",
     "iopub.status.idle": "2025-01-19T14:05:53.642212Z",
     "shell.execute_reply": "2025-01-19T14:05:53.641110Z",
     "shell.execute_reply.started": "2025-01-19T14:05:53.623450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "all_sentences = {}\n",
    "\n",
    "for file, data in tqdm(json_data_list[0:]):\n",
    "    sentences = {e['ID']: e['Passage'] for e in data}\n",
    "    all_sentences |= sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:53.644891Z",
     "iopub.status.busy": "2025-01-19T14:05:53.644613Z",
     "iopub.status.idle": "2025-01-19T14:05:53.649338Z",
     "shell.execute_reply": "2025-01-19T14:05:53.648235Z",
     "shell.execute_reply.started": "2025-01-19T14:05:53.644865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_set = \"test\"\n",
    "rrf_inference_trec_file_path = \"/kaggle/input/regnlp-test-l2/rrf.trec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:53.651147Z",
     "iopub.status.busy": "2025-01-19T14:05:53.650806Z",
     "iopub.status.idle": "2025-01-19T14:05:53.695489Z",
     "shell.execute_reply": "2025-01-19T14:05:53.694433Z",
     "shell.execute_reply.started": "2025-01-19T14:05:53.651118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "questions = {}\n",
    "with open(f\"ObliQADataset/ObliQA_{eval_set}.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "    for each_question in tqdm(data[:]):\n",
    "        questions[each_question['QuestionID']]=(each_question['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:05:53.697731Z",
     "iopub.status.busy": "2025-01-19T14:05:53.697291Z",
     "iopub.status.idle": "2025-01-19T14:05:54.369433Z",
     "shell.execute_reply": "2025-01-19T14:05:54.368572Z",
     "shell.execute_reply.started": "2025-01-19T14:05:53.697676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(rrf_inference_trec_file_path, names=[\"qid\", \"_\", \"pid\", \"ind\", \"score\", \"alg\"], sep=\" \")\n",
    "\n",
    "df['passage'] = df['pid'].apply(lambda e: all_sentences[e])\n",
    "df['question'] = df['qid'].apply(lambda e: questions[e])\n",
    "dtest = df[['question', 'passage']].drop_duplicates().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:06:59.414554Z",
     "iopub.status.busy": "2025-01-19T14:06:59.414156Z",
     "iopub.status.idle": "2025-01-19T14:06:59.652587Z",
     "shell.execute_reply": "2025-01-19T14:06:59.651507Z",
     "shell.execute_reply.started": "2025-01-19T14:06:59.414520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "model = model.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:15:55.480892Z",
     "iopub.status.busy": "2025-01-19T14:15:55.480463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "batch_size = 1\n",
    "with torch.no_grad():\n",
    "    for e in tqdm(range(0, len(dtest), batch_size)):\n",
    "        batch_sentences1 = [each_sample[0] for each_sample in dtest[e:e+batch_size]]\n",
    "        batch_sentences2 = [each_sample[1] for each_sample in dtest[e:e+batch_size]]\n",
    "        tokens = tokenizer(batch_sentences1, batch_sentences2,  padding=True, return_tensors='pt')\n",
    "        if tokens['input_ids'].shape[1] > 512:\n",
    "            tokens = tokenizer(batch_sentences1, batch_sentences2, padding='max_length', return_tensors='pt', max_length=512, truncation=True)\n",
    "    \n",
    "        tokens = tokens.to('cuda')\n",
    "    \n",
    "        batch_score = (model(**tokens).logits.detach().cpu()).numpy()\n",
    "        scores.append(batch_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trec File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T14:07:17.049594Z",
     "iopub.status.busy": "2025-01-19T14:07:17.048813Z",
     "iopub.status.idle": "2025-01-19T14:07:17.905560Z",
     "shell.execute_reply": "2025-01-19T14:07:17.904046Z",
     "shell.execute_reply.started": "2025-01-19T14:07:17.049557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_scores = {}\n",
    "c = 0\n",
    "for e0, e1 in zip(dtest, scores):\n",
    "    final_scores[\":\".join(e0)] = e1[0]\n",
    "\n",
    "df['l2_score'] = df.apply(lambda e: final_scores[e['question']+\":\"+e['passage']], axis=1)\n",
    "\n",
    "df[['qid', '_', 'pid', 'ind', 'l2_score', 'alg']].drop_duplicates(subset=[\"qid\", \"pid\"]).to_csv(\"l2.trec\", header=False, index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-19T13:32:35.111100Z",
     "iopub.status.idle": "2025-01-19T13:32:35.111400Z",
     "shell.execute_reply": "2025-01-19T13:32:35.111277Z",
     "shell.execute_reply.started": "2025-01-19T13:32:35.111263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!trec_eval/trec_eval -m recall.10 -m map_cut.10 /kaggle/input/regnlp-test-l2/gt.qrels ./l2.trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6157523,
     "sourceId": 10003491,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6157683,
     "sourceId": 10003533,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 210528975,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
